{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "theoretical-january",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "accurate-bathroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Datasets:\n",
    "    files = dict(\n",
    "        IRIS = './iris.csv',\n",
    "        MNIST = './mnist.csv',\n",
    "        BANK_NOTE = './bank_note.csv',\n",
    "        BREAST_CANCER = './breast_cancer.csv'\n",
    "    )\n",
    "    \n",
    "    \n",
    "    targets = dict(\n",
    "        IRIS_TARGET = 'species_coded',\n",
    "        MNIST_TARGET = 'label',\n",
    "        BANK_NOTE_TARGET = 'class',\n",
    "        BREAST_CANCER_TARGET = 'diagnosis_coded'\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "finnish-crawford",
   "metadata": {
    "code_folding": [
     24
    ]
   },
   "outputs": [],
   "source": [
    "def import_dataset(filename: str) -> pd.DataFrame:\n",
    "    '''Import dataset specified by the filename.\n",
    "    \n",
    "    Format of the dataset should be '.csv'\n",
    "    '''\n",
    "    return pd.read_csv(filename, sep=',')\n",
    "\n",
    "def normalize(dataset: pd.DataFrame)-> pd.DataFrame:\n",
    "    scaler = MinMaxScaler()\n",
    "    new_data = scaler.fit_transform(dataset)\n",
    "    return pd.DataFrame(new_data, columns=dataset.columns)\n",
    "\n",
    "def split(X, y):\n",
    "    '''Perform train test split in ratio 80:20\n",
    "    '''\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=40)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def init_params(size, variance=1.0):\n",
    "    '''Initialize parameters (weights or bias) using normal distribution with mean=0\n",
    "    and variance=1.0\n",
    "    '''\n",
    "    return tf.Variable((tf.random.normal(size) * variance))\n",
    "\n",
    "class NeuralNetwork:\n",
    "    \n",
    "    learning_rate = tf.constant([10e-4])\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.w1 = []\n",
    "        self.b1 = []\n",
    "        self.w2 = []\n",
    "        self.b2 = []\n",
    "        self.w3 = []\n",
    "        self.k0  = 0\n",
    "        self.k1  = 0\n",
    "    \n",
    "    def _init_params(self, size, variance=1.0):\n",
    "        '''Return a tensorflow variable with value from normal distribution with mean=0\n",
    "        and variance=1.0 with corresponding size\n",
    "        '''\n",
    "        return tf.Variable((tf.random.normal(size) * variance))\n",
    "    \n",
    "    def _init_weights_and_bias(self, input_shape: int, output_neurons: int, hidden_1: int, hidden_2: int):\n",
    "        '''Initialize weights and bias'''\n",
    "        self.w1 = self._init_params((input_shape, hidden_1))\n",
    "        self.b1 = self._init_params([1])\n",
    "        \n",
    "        self.w2 = self._init_params((hidden_1, hidden_2))\n",
    "        self.b2 = self._init_params([1])\n",
    "        \n",
    "        self.w3 = self._init_params((hidden_2, output_neurons))\n",
    "        self.k0 = self._init_params([1])\n",
    "        self.k1 = self._init_params([1])\n",
    "    \n",
    "    def _activation_function(self, x):\n",
    "        '''Custom activation function'''\n",
    "        return self.k0 + self.k1*x\n",
    "    \n",
    "    def _build_model(self, X_train: pd.DataFrame, y_train: pd.Series, num_classes=2):\n",
    "        '''Build a neural network with 1 hidden layer'''\n",
    "        hidden_layer1_size: int = 2\n",
    "        hidden_layer2_size: int = 2\n",
    "        output_size = num_classes\n",
    "        if num_classes <= 2:\n",
    "            output_size = 1\n",
    "        \n",
    "        self._init_weights_and_bias(X_train.shape[1], output_size, hidden_layer1_size, hidden_layer2_size)\n",
    "        \n",
    "    def _forward_propagation(self, X_batch, y_batch, class_type='binary'):\n",
    "        l1 = tf.linalg.matmul(X_batch, self.w1) + self.b1\n",
    "        a1 = self._activation_function(l1)\n",
    "        \n",
    "        l2 = tf.linalg.matmul(a1, self.w2) + self.b2\n",
    "        a2 = self._activation_function(l2)\n",
    "        \n",
    "        l3 = tf.linalg.matmul(a2, self.w3)\n",
    "        \n",
    "        forwprop_vals = dict(\n",
    "            l1 = l1,\n",
    "            a1 = a1,\n",
    "            l2 = l2,\n",
    "            a2 = a2,\n",
    "            l3 = l3\n",
    "        )\n",
    "        if class_type == 'binary':\n",
    "            return tf.math.sigmoid(l3), forwprop_vals\n",
    "        else:\n",
    "            return tf.nn.softmax(l3), forwprop_vals\n",
    "    \n",
    "    def _loss_calc(self, loss: str, y_true, y_pred):\n",
    "        if loss == 'binary_crossentropy':\n",
    "            return tf.keras.losses.binary_crossentropy(y_true, y_pred)\n",
    "        else:\n",
    "            return tf.keras.losses.categorical_crossentropy(y_true, y_pred)\n",
    "        \n",
    "    def _backward_propagation(self, tape, loss, forwardProp_eqns):\n",
    "        dw1, db1, dw2, db2, dw3, da1, da2 = tape.gradient(loss, \n",
    "                                                [self.w1, self.b1, self.w2, self.b2, self.w3, \n",
    "                                                 forwardProp_eqns['a1'], forwardProp_eqns['a2']])\n",
    "        \n",
    "        dK = [\n",
    "            tf.math.reduce_mean(da1) + tf.math.reduce_mean(da2),\n",
    "            tf.math.reduce_mean(da1 * forwardProp_eqns['l1']) + tf.math.reduce_mean(da2 * forwardProp_eqns['l2'])\n",
    "        ]\n",
    "        \n",
    "        return dict(\n",
    "            grad_w1 = dw1, \n",
    "            grad_b1 = db1, \n",
    "            grad_w2 = dw2, \n",
    "            grad_b2 = db2, \n",
    "            grad_w3 = dw3,\n",
    "            grad_K = dK\n",
    "        )\n",
    "    \n",
    "    def _update_params(self, grads: dict):\n",
    "        self.w1.assign_sub(grads['grad_w1'] * NeuralNetwork.learning_rate)\n",
    "        self.b1.assign_sub(grads['grad_b1'] * NeuralNetwork.learning_rate)\n",
    "        self.w2.assign_sub(grads['grad_w2'] * NeuralNetwork.learning_rate)\n",
    "        self.b2.assign_sub(grads['grad_b2'] * NeuralNetwork.learning_rate)\n",
    "        self.w3.assign_sub(grads['grad_w3'] * NeuralNetwork.learning_rate)\n",
    "        self.k0.assign_sub(grads['grad_K'][0] * NeuralNetwork.learning_rate)\n",
    "        self.k1.assign_sub(grads['grad_K'][1] * NeuralNetwork.learning_rate)\n",
    "        \n",
    "    def _batch_split(self, batch_size, iter_num, X_train: pd.DataFrame, y_train):\n",
    "        rem = (iter_num+1)*batch_size\n",
    "        if (iter_num+1)*batch_size > X_train.shape[0]:\n",
    "            rem = X_train.shape[0]\n",
    "        X_batch = X_train.iloc(axis=0)[iter_num*batch_size:rem]\n",
    "        if type(y_train) == pd.Series:\n",
    "            y_batch = y_train.iloc[iter_num*batch_size:rem]\n",
    "            y_batch = np.reshape(y_batch.values, (y_batch.shape[0], 1))\n",
    "        else:\n",
    "            y_batch = y_train[iter_num*batch_size:rem]\n",
    "        \n",
    "        X_batch = X_batch.values.astype('float32')\n",
    "        \n",
    "        return X_batch, y_batch\n",
    "        \n",
    "    def fit(self, X_train: pd.DataFrame, y_train, epochs: int = 100, class_type='binary', num_classes=2):\n",
    "        \n",
    "        batch_size = 50\n",
    "        \n",
    "        if class_type != 'binary':\n",
    "            loss_type = 'categorical_crossentropy'\n",
    "        else:\n",
    "            loss_type = 'binary_crossentropy'\n",
    "        \n",
    "        # Build the model\n",
    "        self._build_model(X_train, y_train, num_classes=num_classes)\n",
    "        \n",
    "        losses = []\n",
    "        \n",
    "        for i in range(epochs):\n",
    "            with tf.GradientTape(persistent=True) as tape:\n",
    "                for j in range(X_train.shape[0] // batch_size):\n",
    "                    X_batch, y_batch = self._batch_split(batch_size, j, X_train, y_train)\n",
    "                    \n",
    "                    # Forward prop\n",
    "                    predictions, forwardProp_eqns = self._forward_propagation(X_batch, y_batch, class_type)\n",
    "#                     print(y_batch, predictions)\n",
    "                    #Loss Calculation\n",
    "                    loss = self._loss_calc(loss_type, y_batch, predictions)\n",
    "#                     print(loss)\n",
    "                    # Backward Prop\n",
    "                    gradients = self._backward_propagation(tape, loss, forwardProp_eqns)\n",
    "\n",
    "                    # Parameter update\n",
    "                    self._update_params(gradients)\n",
    "                    \n",
    "            losses.append(np.sum(loss.numpy()))\n",
    "                \n",
    "        return losses\n",
    "        \n",
    "    def predict(self, X_test: pd.DataFrame):\n",
    "        pass\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "marked-university",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = import_dataset(Datasets.files['MNIST'])\n",
    "X_cols = [col for col in data.columns if col != Datasets.targets['MNIST_TARGET']]\n",
    "y_col = Datasets.targets['MNIST_TARGET']\n",
    "\n",
    "X, y = data[X_cols], data[y_col]\n",
    "num_labels = len(y.unique())\n",
    "if len(y.unique()) > 2:\n",
    "    y = tf.one_hot(tf.constant(y.values, tf.int32), depth=len(y.unique())).numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = split(X, y)\n",
    "\n",
    "X_train, X_test = normalize(X_train), normalize(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "bored-magazine",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "neuralNet = NeuralNetwork()\n",
    "losses = neuralNet.fit(X_train, y_train, class_type='categorical', num_classes=num_labels)\n",
    "\n",
    "plt.plot(list(range(len(losses))), losses)\n",
    "plt.ylabel('loss')\n",
    "plt.title('Loss v/s Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
